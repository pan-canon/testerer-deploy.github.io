export class CameraManager {
  constructor(videoElementId) {
    this.videoElement = document.getElementById(videoElementId);
    this.stream = null;
  }

async start() {
    try {
        const isMobile = /Android|iPhone|iPad|iPod/i.test(navigator.userAgent);
        const constraints = {
            video: { facingMode: isMobile ? "environment" : "user" }
        };

        console.log(`üé• –ó–∞–ø—É—Å–∫ –∫–∞–º–µ—Ä—ã: ${constraints.video.facingMode}`);
        this.stream = await navigator.mediaDevices.getUserMedia(constraints);

        if (!this.videoElement) {
            console.error("üö® –û—à–∏–±–∫–∞: videoElement –Ω–µ –Ω–∞–π–¥–µ–Ω!");
            return;
        }

        this.videoElement.srcObject = this.stream;
    } catch (error) {
        console.error("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ—Å—Ç—É–ø–µ –∫ –∫–∞–º–µ—Ä–µ:", error);
    }
}


async loadSelfieEmbedding(selfieSrc) {
    if (!selfieSrc) {
        console.warn("‚ùå –°–µ–ª—Ñ–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç!");
        return null;
    }

    // –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–µ–ª—Ñ–∏
    const img = new Image();
    img.src = selfieSrc;
    await new Promise(resolve => img.onload = resolve);

    // –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    const model = await faceLandmarksDetection.load(
        faceLandmarksDetection.SupportedPackages.mediapipeFacemesh
    );

    // –ü–æ–ª—É—á–∞–µ–º –ª–∏—Ü–æ
    const predictions = await model.estimateFaces({ input: img });

    if (!predictions.length) {
        console.warn("‚ùå –õ–∏—Ü–æ –Ω–∞ —Å–µ–ª—Ñ–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ!");
        return null;
    }

    console.log("üì∏ –õ–∏—Ü–æ –Ω–∞ —Å–µ–ª—Ñ–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–æ:", predictions[0].scaledMesh);
    return predictions[0].scaledMesh; // –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –ª–∏—Ü–∞
}


async compareFaces(videoElement, selfieEmbedding) {
    if (!videoElement || !selfieEmbedding) {
        console.warn("‚ö†Ô∏è –ö–∞–º–µ—Ä–∞ –∏–ª–∏ —Å–µ–ª—Ñ–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç!");
        return false;
    }

    // –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    const model = await faceLandmarksDetection.load(
        faceLandmarksDetection.SupportedPackages.mediapipeFacemesh
    );

    // –ü–æ–ª—É—á–∞–µ–º –ª–∏—Ü–æ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
    const predictions = await model.estimateFaces({ input: videoElement });

    if (!predictions.length) {
        console.warn("‚ùå –õ–∏—Ü–æ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ!");
        return false;
    }

    console.log("üìπ –õ–∏—Ü–æ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏:", predictions[0].scaledMesh);

    // ‚úÖ –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É —Ç–æ—á–∫–∞–º–∏ –ª–∏—Ü–∞ (–µ–≤–∫–ª–∏–¥–æ–≤–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ)
    let distance = 0;
    for (let i = 0; i < selfieEmbedding.length; i++) {
        distance += Math.pow(selfieEmbedding[i][0] - predictions[0].scaledMesh[i][0], 2);
        distance += Math.pow(selfieEmbedding[i][1] - predictions[0].scaledMesh[i][1], 2);
        distance += Math.pow(selfieEmbedding[i][2] - predictions[0].scaledMesh[i][2], 2);
    }
    distance = Math.sqrt(distance / selfieEmbedding.length);

    console.log("üìè –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –ª–∏—Ü–∞–º–∏:", distance);

    return distance < 20; // üîπ –ï—Å–ª–∏ –º–µ–Ω—å—à–µ 20 ‚Äî –ª–∏—Ü–∞ —Å–æ–≤–ø–∞–¥–∞—é—Ç!
}



  stop() {
    if (this.stream) {
      this.stream.getTracks().forEach(track => track.stop());
      this.stream = null;
    }
  }
}