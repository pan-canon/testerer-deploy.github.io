<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Face-api.js Example</title>
  <script src="js/libs/face-api.js"></script>
</head>
<body>
  <h1>Face-api.js Example</h1>
  <button id="capture">Capture Selfie</button>
  <button id="compare">Compare with Camera</button>
  <video id="video" width="640" height="480" autoplay></video>
  <canvas id="canvas" style="display: none;"></canvas>

  <script>
    let videoElement = document.getElementById("video");
    let captureButton = document.getElementById("capture");
    let compareButton = document.getElementById("compare");
    let selfieImage = null; // Для хранения селфи
    let selfieDescriptor = null; // Для хранения дескриптора лица из селфи

    // Инициализация камеры
    async function setupCamera() {
      console.log("Setting up camera...");
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      videoElement.srcObject = stream;
      await new Promise(resolve => videoElement.onplaying = resolve);
      console.log("Camera ready");
    }

    // Загружаем модели
    async function loadModels() {
      console.log("Loading models...");
      try {
        await Promise.all([
          faceapi.nets.ssdMobilenetv1.loadFromUri('./models'),
          faceapi.nets.faceLandmark68Net.loadFromUri('./models'),
          faceapi.nets.faceRecognitionNet.loadFromUri('./models')
        ]);
        console.log("Models loaded");
      } catch (error) {
        console.log("Error loading models:", error);
      }
    }

    // Запуск инициализации камеры и моделей
    async function init() {
      await setupCamera();
      await loadModels();
      console.log("Models loaded and camera set up, ready to capture!");
    }

    // Селфи: захват кадра с камеры и сохранение в формате base64
// Селфи: захват кадра с камеры и сохранение в формате base64
// Селфи: захват кадра с камеры и сохранение в формате base64
// Селфи: захват кадра с камеры и сохранение в формате base64
// Селфи: захват кадра с камеры и сохранение в формате base64
captureButton.addEventListener("click", async () => {
  console.log("Capturing selfie...");
  const canvas = document.createElement('canvas');
  canvas.width = videoElement.videoWidth;
  canvas.height = videoElement.videoHeight;
  const ctx = canvas.getContext('2d');
  ctx.drawImage(videoElement, 0, 0, canvas.width, canvas.height);
  selfieImage = canvas.toDataURL();
  console.log("Selfie captured:", selfieImage);

  // Преобразуем строку base64 в объект Image
  const img = new Image();
  img.src = selfieImage;
  await new Promise(resolve => {
    img.onload = () => {
      console.log("Image loaded successfully");
      resolve();
    };
  });

  // Проверяем, обнаружено ли лицо на селфи
  const detections = await detectFace(img);
  console.log("Face detections on selfie:", detections);

  if (detections.length > 0) {
    selfieDescriptor = detections[0].descriptor;
    console.log("Selfie descriptor captured:", selfieDescriptor);
  } else {
    console.log("No face detected in selfie");
  }
});

// Функция для обнаружения лица и получения дескрипторов
async function detectFace(imageData) {
  console.log("Detecting face on image...");
  const detections = await faceapi.detectAllFaces(imageData)
    .withFaceLandmarks()
    .withFaceDescriptors();
  
  console.log("Detection results:", detections);
  
  if (detections && detections.length > 0) {
    return detections;
  } else {
    console.log("No faces detected in this image.");
    return [];
  }
}

// Сравнение селфи с текущим кадром
captureButton.addEventListener("click", async () => {
  console.log("Capturing selfie...");
  const canvas = document.createElement('canvas');
  canvas.width = videoElement.videoWidth;
  canvas.height = videoElement.videoHeight;
  const ctx = canvas.getContext('2d');
  ctx.drawImage(videoElement, 0, 0, canvas.width, canvas.height);
  selfieImage = canvas.toDataURL();
  console.log("Selfie captured:", selfieImage);

  // Преобразуем строку base64 в объект Image
  const img = new Image();
  img.src = selfieImage;
  await new Promise(resolve => {
    img.onload = () => {
      console.log("Image loaded successfully");
      resolve();
    };
  });

  // Проверяем, обнаружено ли лицо на селфи
  const detections = await detectFace(img);
  console.log("Face detections on selfie:", detections);

  if (detections.length > 0) {
    selfieDescriptor = detections[0].descriptor;
    console.log("Selfie descriptor captured:", selfieDescriptor);
  } else {
    console.log("No face detected in selfie");
  }
});

// Функция для обнаружения лица и получения дескрипторов
async function detectFace(imageData) {
  console.log("Detecting face on image...");
  const detections = await faceapi.detectAllFaces(imageData)
    .withFaceLandmarks()
    .withFaceDescriptors();
  
  console.log("Detection results:", detections);
  
  if (detections && detections.length > 0) {
    return detections;
  } else {
    console.log("No faces detected in this image.");
    return [];
  }
}

// Сравнение селфи с текущим кадром
// Захват селфи
captureButton.addEventListener("click", async () => {
  console.log("Capturing selfie...");
  const canvas = document.createElement('canvas');
  canvas.width = videoElement.videoWidth;
  canvas.height = videoElement.videoHeight;
  const ctx = canvas.getContext('2d');
  ctx.drawImage(videoElement, 0, 0, canvas.width, canvas.height);
  selfieImage = canvas.toDataURL();
  console.log("Selfie captured:", selfieImage);

  // Преобразуем строку base64 в объект Image
  const img = new Image();
  img.src = selfieImage;
  await new Promise(resolve => {
    img.onload = () => {
      console.log("Image loaded successfully");
      resolve();
    };
  });

  // Проверяем лицо на изображении
  const detections = await detectFace(img);
  console.log("Face detections on selfie:", detections);

  if (detections.length > 0) {
    selfieDescriptor = detections[0].descriptor;
    console.log("Selfie descriptor captured:", selfieDescriptor);
  } else {
    console.log("No face detected in selfie");
  }
});

// Функция для обнаружения лица и получения дескрипторов
async function detectFace(imageData) {
  console.log("Detecting face on image...");
  const detections = await faceapi.detectAllFaces(imageData)
    .withFaceLandmarks()
    .withFaceDescriptors();
  
  console.log("Detection results:", detections);
  
  if (detections && detections.length > 0) {
    return detections;
  } else {
    console.log("No faces detected in this image.");
    return [];
  }
}

// Сравнение с живым потоком
// Сохранение селфи и дескриптора в localStorage
captureButton.addEventListener("click", async () => {
  console.log("Capturing selfie...");
  const canvas = document.createElement('canvas');
  canvas.width = videoElement.videoWidth;
  canvas.height = videoElement.videoHeight;
  const ctx = canvas.getContext('2d');
  ctx.drawImage(videoElement, 0, 0, canvas.width, canvas.height);
  selfieImage = canvas.toDataURL();
  console.log("Selfie captured:", selfieImage);

  const img = new Image();
  img.src = selfieImage;
  await new Promise(resolve => {
    img.onload = () => {
      console.log("Image loaded successfully");
      resolve();
    };
  });

  const detections = await detectFace(img);
  console.log("Face detections on selfie:", detections);

  if (detections.length > 0) {
    selfieDescriptor = detections[0].descriptor;
    console.log("Selfie descriptor captured:", selfieDescriptor);

    // Сохраняем в localStorage
    localStorage.setItem('selfie', selfieImage);
    localStorage.setItem('selfieDescriptor', JSON.stringify(selfieDescriptor));
    console.log("Selfie and descriptor saved to localStorage");
  } else {
    console.log("No face detected in selfie");
  }
});

// Сравнение с сохраненным селфи
compareButton.addEventListener("click", async () => {
  console.log("Comparing with saved selfie...");

  // Извлекаем сохраненные данные из localStorage
  const savedSelfie = localStorage.getItem('selfie');
  const savedSelfieDescriptor = JSON.parse(localStorage.getItem('selfieDescriptor'));

  if (!savedSelfie || !savedSelfieDescriptor) {
    console.log("No selfie found in localStorage. Capture a selfie first.");
    return;
  }

  // Преобразуем сохранённое селфи обратно в изображение
  const img = new Image();
  img.src = savedSelfie;
  await new Promise(resolve => {
    img.onload = () => {
      console.log("Saved selfie loaded successfully");
      resolve();
    };
  });

  // Получаем дескриптор для текущего кадра с камеры
  const currentDetections = await detectFace(img);
  console.log("Face detections on current frame:", currentDetections);

  if (currentDetections.length > 0) {
    const currentDescriptor = currentDetections[0].descriptor;
    console.log("Current descriptor:", currentDescriptor);

    // Сравниваем дескрипторы
    const distance = faceapi.euclideanDistance(savedSelfieDescriptor, currentDescriptor);
    console.log("Distance between descriptors:", distance);

    if (distance < 0.6) {
      console.log("Faces match!");
    } else {
      console.log("Faces do not match.");
    }
  } else {
    console.log("No face detected in current frame.");
  }
});





// Функция для обнаружения лица и получения дескрипторов
async function detectFace(imageData) {
  console.log("Detecting face on image...");
  const detections = await faceapi.detectAllFaces(imageData)
    .withFaceLandmarks()
    .withFaceDescriptors();
  console.log("Detection results:", detections);
  return detections;
}

// Сравнение селфи с текущим кадром
compareButton.addEventListener("click", async () => {
  if (!selfieDescriptor) {
    console.log("No selfie captured to compare with.");
    return;
  }

  console.log("Comparing selfie with live camera feed...");

  const liveDetections = await detectFace(videoElement);
  console.log("Live face detections:", liveDetections);

  if (liveDetections.length > 0) {
    const liveDescriptor = liveDetections[0].descriptor;

    // Сравниваем дескрипторы
    const distance = faceapi.euclideanDistance(selfieDescriptor, liveDescriptor);
    console.log("Face similarity:", distance);

    if (distance < 0.6) {
      console.log("Faces match!");
    } else {
      console.log("Faces do not match.");
    }
  } else {
    console.log("No face detected in the live camera feed.");
  }
});




    // Сравнение селфи с текущим кадром
    compareButton.addEventListener("click", async () => {
      if (!selfieDescriptor) {
        console.log("No selfie captured to compare with.");
        return;
      }

      console.log("Comparing selfie with live camera feed...");

      const liveDetections = await detectFace(videoElement);
      if (liveDetections.length > 0) {
        const liveDescriptor = liveDetections[0].descriptor;

        // Сравниваем дескрипторы
        const distance = faceapi.euclideanDistance(selfieDescriptor, liveDescriptor);
        console.log("Face similarity:", distance);

        if (distance < 0.6) { // Снижение порога для совпадений
          console.log("Faces match!");
        } else {
          console.log("Faces do not match.");
        }
      } else {
        console.log("No face detected in the live camera feed.");
      }
    });

    // Функция для обнаружения лица и получения дескрипторов
    async function detectFace(imageData) {
      const img = new Image();
      img.src = imageData;
      await new Promise(resolve => img.onload = resolve);
      const detections = await faceapi.detectAllFaces(img)
        .withFaceLandmarks()
        .withFaceDescriptors();
      return detections;
    }

    // Запуск инициализации
    init();
  </script>
</body>
</html>
