<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Face-api.js Example</title>
  <script src="js/libs/face-api.js"></script>
</head>
<body>
  <h1>Face-api.js Example</h1>
  <button id="capture">Capture Selfie</button>
  <button id="compare">Compare with Camera</button>
  <video id="video" width="640" height="480" autoplay></video>
  <canvas id="canvas" style="display: none;"></canvas>

  <script>
    let videoElement = document.getElementById("video");
    let captureButton = document.getElementById("capture");
    let compareButton = document.getElementById("compare");
    let selfieImage = null; // Для хранения селфи
    let selfieDescriptor = null; // Для хранения дескриптора лица из селфи

    // Инициализация камеры
    async function setupCamera() {
      console.log("Setting up camera...");
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      videoElement.srcObject = stream;
      await new Promise(resolve => videoElement.onplaying = resolve);
      console.log("Camera ready");
    }

    // Загружаем модели
    async function loadModels() {
      console.log("Loading models...");
      try {
        await Promise.all([
          faceapi.nets.ssdMobilenetv1.loadFromUri('./models'),
          faceapi.nets.faceLandmark68Net.loadFromUri('./models'),
          faceapi.nets.faceRecognitionNet.loadFromUri('./models')
        ]);
        console.log("Models loaded");
      } catch (error) {
        console.log("Error loading models:", error);
      }
    }

    // Запуск инициализации камеры и моделей
    async function init() {
      await setupCamera();
      await loadModels();
      console.log("Models loaded and camera set up, ready to capture!");
    }

    // Селфи: захват кадра с камеры и сохранение в формате base64
    captureButton.addEventListener("click", async () => {
      console.log("Capturing selfie...");
      const canvas = document.createElement('canvas');
      canvas.width = videoElement.videoWidth;
      canvas.height = videoElement.videoHeight;
      const ctx = canvas.getContext('2d');
      ctx.drawImage(videoElement, 0, 0, canvas.width, canvas.height);
      selfieImage = canvas.toDataURL();
      console.log("Selfie captured:", selfieImage);

      // Преобразуем строку base64 в объект Image
      const img = new Image();
      img.src = selfieImage;
      await new Promise(resolve => {
        img.onload = () => {
          console.log("Image loaded successfully");
          resolve();
        };
      });

      // Проверяем, обнаружено ли лицо на селфи
      const detections = await detectFace(img);
      console.log("Face detections on selfie:", detections);

      if (detections.length > 0) {
        selfieDescriptor = detections[0].descriptor;
        console.log("Selfie descriptor captured:", selfieDescriptor);

        // Сохраняем селфи в localStorage
        localStorage.setItem('selfie', selfieImage);
        localStorage.setItem('selfieDescriptor', JSON.stringify(selfieDescriptor));
        console.log("Selfie and descriptor saved to localStorage");
      } else {
        console.log("No face detected in selfie");
      }
    });

    // Функция для обнаружения лица и получения дескрипторов
    async function detectFace(imageData) {
      console.log("Detecting face on image...");
      const detections = await faceapi.detectAllFaces(imageData)
        .withFaceLandmarks()
        .withFaceDescriptors();
      
      console.log("Detection results:", detections);
      
      if (detections && detections.length > 0) {
        return detections;
      } else {
        console.log("No faces detected in this image.");
        return [];
      }
    }

    // Сравнение селфи с текущим кадром
    compareButton.addEventListener("click", async () => {
      console.log("Comparing with saved selfie...");

      // Загружаем сохранённое селфи из localStorage
      const savedSelfie = localStorage.getItem('selfie');
      const savedDescriptor = JSON.parse(localStorage.getItem('selfieDescriptor'));

      if (!savedSelfie || !savedDescriptor) {
        console.log("No selfie found in localStorage. Capture a selfie first.");
        return;
      }

      // Преобразуем сохранённое селфи в изображение
      const img = new Image();
      img.src = savedSelfie;
      await new Promise(resolve => {
        img.onload = () => resolve();
      });

      // Получаем дескриптор для текущего кадра с камеры
      const detections = await detectFace(img);
      if (detections.length > 0) {
        const currentDescriptor = detections[0].descriptor;

        // Сравниваем дескрипторы
        const distance = faceapi.euclideanDistance(savedDescriptor, currentDescriptor);

        if (distance < 0.6) {
          console.log("This is the same person!");
        } else {
          console.log("This is a different person.");
        }
      } else {
        console.log("No face detected in the current frame.");
      }
    });

    // Запуск инициализации
    init();
  </script>
</body>
</html>
